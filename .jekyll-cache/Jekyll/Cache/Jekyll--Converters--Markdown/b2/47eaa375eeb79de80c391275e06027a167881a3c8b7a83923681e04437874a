I"M<p>The content in this page is based on the following report.
<i style="font-size:24px" class="fa">ÔáÅ</i></p>

<h1 id="introduction">Introduction</h1>

<p>Various SLAM algorithms such as Hector SLAM, Gmapping, Cartographer, RTAB-Map and ORB-SLAM 3 were explored to create a map of school tunnel. Data of the school tunnel were collected by a LiDAR, Cameras, and IMU. The sensor data were stored as a rosbag format to test the algorithms individually by replaying the rosbag file on ROS. Each algorithm created either occupancy grid map or point cloud map and their performance was analyzed.</p>

<h1 id="data-collection">Data Collection</h1>

<p style="text-align: center;"><img src="/assets/projects/School-Tunnel.png" width="250" height="250" /><strong><br />Route and map of school tunnel.</strong></p>
<p>The school tunnel at Northeastern University looked like the map above. The red line in the map indicated where the sensor data were collected and the algorithms had to contruct a map.</p>

<p style="text-align: center;"><img src="/assets/projects/RPLiDAR-A3.png" width="150" height="150" /><img src="/assets/projects/Realsense-D435i.png" width="150" height="150" /><img src="/assets/projects/Realsense-T265.png" width="150" height="150" /><img src="/assets/projects/VectorNav-VN100.png" width="150" height="150" /><strong><br />RPLiDAR A3, Realsense D435i and T265, and VectorNav VN100 sensors from the left.</strong></p>

<p>The sensors consisted of one LiDAR, two cameras, and one IMU. RPLiDAR A3 was a 2D planar LiDAR. Realsense D435i and T265 were a RGB-D and Stereo camera respectively. VectorNav VN100 was an IMU that contained a three-axis accelerometer, gyroscope, and magnetometer.</p>

<p style="text-align: center;"><img src="/assets/projects/Sensor-Mount-Top.png" width="400" height="400" /><img src="/assets/projects/Sensor-Mount-Front.png" width="155" height="155" /><strong><br />Top side of the cart with the LiDAR and IMU and front side with the cameras.</strong></p>

<p>The sensors were rigidly mounted on a rolling cart as the figures above to reduce noises as much as possible. The cart was pushed and traveled the tunnel following the trajectory planned in the beginning. During the sensor data collection, A laptop was reading all the data running ROS drivers for each sensor and recording them with a rosbag node.</p>

<p style="text-align: center;"><img src="/assets/projects/Tunnel-Rosbag.png" width="400" height="400" /><strong><br />Rosbag file recorded.</strong></p>

<h1 id="hector-slam">Hector SLAM</h1>
<p>There was a ROS package implementing Hector SLAM which was a LiDAR based SLAM algorithm. Only the LiDAR sensor data was used and the localization and mapping was performed by scan match. Scan matching was finding the sensor pose that minimized the error between the map and the new scan data using the Gauss-Newton leaster squares approach. This meant that feature detection or mathcning wasn‚Äôt required which reduced the computational load.</p>

<p style="text-align: center;"><img src="/assets/projects/Hector-SLAM-1.png" width="400" height="400" /><img src="/assets/projects/Hector-SLAM-2.png" width="400" height="400" /><strong><br />Left: First 30 seconds of dataset showing good SLAM performance. Right: Entire map with some incorrect pose estimation.</strong></p>

<p>Hector SLAM generated and expanded the map as the cart moved along and provided fair pose information. However, during the travel in long and straight sections of the tunnel, it wasn‚Äôt able to function properly since there were no distinct differences in the consecutive LiDAR scans and the cart was assumed to be stationary.</p>

<h1 id="gmapping-slam">Gmapping SLAM</h1>
<p>Another LiDAR based SLAM, Gmapping SLAM, was tested. It applied a Rao-Blackwellized particle filter for learning grid maps and created a 2D occupancy grid map from the laser scan and pose data. In ROS, the Gmapping SLAM node which was called <code class="language-plaintext highlighter-rouge">slam_gmapping</code> attempted to transform each incoming scan into the <code class="language-plaintext highlighter-rouge">odom</code> tf frame.</p>

<p>Additional ROS node was required to provide accurate pose data to the Gmapping SLAM node. It was called <code class="language-plaintext highlighter-rouge">laser_scan_matcher_node</code> from the <code class="language-plaintext highlighter-rouge">laser_scan_matcher</code> package. This package was an incremental laser scan registration tool. It allowed to scan match between consecutive <code class="language-plaintext highlighter-rouge">sensor_msgs/LaserScan</code> messages and published the estimated pose of the sensor with a tf transform. Detailed instruction for running the Gmapping SLAM node can be found in <a href="#appendix-a-gmapping-slam-in-ros">Appendix A</a>.</p>

<p style="text-align: center;"><img src="/assets/projects/Gmapping-SLAM.png" width="250" height="250" /><strong><br />Map generated from Gmapping SLAM.</strong></p>
<p>The resulting map presented the same issue as Hector SLAM. When there were no distinctive differences between consecutive laser scan messages, the cart was assumed to stationary. Therefore, some tunnel areas were generated on top of the wrong locations and the entire map ended up having several overlapping areas.</p>

<h1 id="cartographer-slam">Cartographer SLAM</h1>
<p>Cartographer SLAM used a combitionation of LiDAR and IMU data to construct 2D or 3D map of the environment while simultaneously estimating poses of the sensors. Detailed instruction for running the Cartographer SLAM node on ROS can be found in <a href="#appendix-b-cartographer-slam-in-ros">Appendix B</a>.</p>

<p style="text-align: center;"><img src="/assets/projects/Cartographer-SLAM.png" width="300" height="300" /><strong><br />Map generated from Cartographer SLAM.</strong></p>

<p>Since the IMU data were used, the long and straight sections of the tunnel were mapped more accurately than the last two SLAM algorithms. However, whenever there was a turn, some drifts in the sensor orientation occurred. The Cartographer node had an internal IMU tracker and scan matching functions to estimate poses and the internal functions were too sensitive to rotations. For instance, when the sensor rotated 90 degrees, the estimated rotation was about 180 degrees. Therefore, the algorithm couldn‚Äôt achieve a loop closure and the map ended up having wrong rotation results.</p>

<h1 id="rtab-map">RTAB-Map</h1>
<p>RTAB-Map (Real-Time Appearance-Based Mapping) provided an open-source Graph-Based SLAM library. It was designed to build 3D maps of environments using different sensors such as a RGB-D camera, stereo camera, and LiDAR sensor. For this experiment, the Realsense D435i camera data were used since RTAB-Map had been fully verified with the same type of cameras.</p>

<p>In this mapping algorithm, a keyframe-based approach was applied for mapping which meant a set of keyframes instead of a dense point cloud was used to represent the environment. This approach reduced the memory usage and computational requirements of the SLAM algorithm. This mapping algorithm also featured visual and loop closures to improve the accuracy of the map. Visual closures were detected by comparing the appearance of images captured by a camera, while loop closures were detected by comparing poses of the keyframes. Detailed instruction for running RTAB-Map on ROS can be found in <a href="#appendix-c-rtab-map-in-ros">Appendix C</a>.</p>

<p style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/l8Z8xgZt3Mc?si=2fxemMPZhNJ0YUig" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><strong>Running RTAB-Map on Rviz.</strong></p>

<p style="text-align: center;"><img src="/assets/projects/RTAB-Map-1.png" width="500" height="500" /><img src="/assets/projects/RTAB-Map-2.png" width="300" height="300" /><strong><br />Map generated from RTAB-Map.</strong></p>

<p>The point cloud map showed a very accurate map of the tunnel providing visual information such as a vending machine and elevator as well. There was a slight deviation in the top right corner of the map where the cart made a 180 degree turn. However, RTAB-Map instantly corrected the drift with visual closure.</p>

<h1 id="orb-slam-3">ORB-SLAM 3</h1>
<p>The ORB-SLAM 3 system was based on the feature-based ORB descriptor and the probablistic mapping approach. Additionally, it provided loop closure detection and semantic segmentation component that identified and categorized objects within the environment.</p>

<p style="text-align: center;"><img src="/assets/projects/ORB-SLAM3-trajectory.png" width="400" height="400" /><strong><br />Trajectory generated from ORB-SLAM 3.</strong></p>

<p>In order to run the ORB-SLAM 3 pacakge on ROS, some dependent packaged such as <code class="language-plaintext highlighter-rouge">Open CV</code>, <code class="language-plaintext highlighter-rouge">Pangolin</code>, and <code class="language-plaintext highlighter-rouge">Egien</code> had to be installed as well. Using the stereo camera data, the trajectory of the cart was acquired as above. During the SLAM operation, the number of the ORB features parameter was set to 1000 in its <code class="language-plaintext highlighter-rouge">yaml</code> file to achieve a better accuracy.</p>

<h1 id="conclusion">Conclusion</h1>

<p style="text-align: center;"><strong>Comparison between the SLAM algorithms used for tunnel mapping.<br /></strong></p>

<table>
  <thead>
    <tr>
      <th>SLAM</th>
      <th>Sensors</th>
      <th>Map type</th>
      <th>Performance</th>
      <th>Classification</th>
      <th>Based on</th>
      <th>Odometry required</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Hector SLAM</td>
      <td>2D Lidar</td>
      <td>Grid</td>
      <td>Bad</td>
      <td>Kalman filter</td>
      <td>EKF</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Gmapping SLAM</td>
      <td>2D Lidar</td>
      <td>Grid</td>
      <td>Bad</td>
      <td>Particle filter</td>
      <td>Fast SLAM</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Cartographer SLAM</td>
      <td>2D Lidar/IMU</td>
      <td>Grid</td>
      <td>Bad</td>
      <td>Optimization based</td>
      <td>Graph SLAM</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>RTAB-Map</td>
      <td>RGB-D camera</td>
      <td>Grid/Point cloud</td>
      <td>Good</td>
      <td>Optimization based</td>
      <td>Graph SLAM</td>
      <td>No</td>
    </tr>
    <tr>
      <td>ORB-SLAM 3</td>
      <td>Stereo camera</td>
      <td>Trajectory</td>
      <td>Good</td>
      <td>Optimization based</td>
      <td>Graph SLAM</td>
      <td>No</td>
    </tr>
  </tbody>
</table>

<h1 id="future-work">Future Work</h1>
<p>For Hector SLAM and Gmapping SLAM, a custom ROS node that provides better odometry data from the IMU could be made to localize the sensor pose more accruately since the odometry data from scan matching wasn‚Äôt working under the featureless environemnts.</p>

<p>For Cartographer SLAM, its internal pose estimation function needs to be tuned to correctly match the rotation of the sensor.</p>

<p>For ORB-SLAM 3, its tracking accuracy was remarkable, but loading the generated map on Rviz needs some tf transformation to accurately match the map frame with the tracking frame.</p>

<p>Finally, the comparision between the algorithms could become more rigorous by adapting ground truth map of the tunnel and calculating errors.</p>

<h1 id="appendix-a-gmapping-slam-in-ros">Appendix A: Gmapping SLAM in ROS</h1>
<p>The following instruction assumes pre-installation and setup of ROS Noetic on Ubuntu 20.04.5.</p>
<h3 id="installing-gmapping-slam-package">Installing Gmapping SLAM package</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>ros-noetic-gmapping
<span class="nb">cd </span>catkin_ws
rosmake gmapping
</code></pre></div></div>

<h3 id="installing-laser_scan_matcher-package">Installing <code class="language-plaintext highlighter-rouge">laser_scan_matcher</code> package</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>ros-noetic-scan-tools
</code></pre></div></div>

<h3 id="running-gmapping-slam">Running Gmapping SLAM</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roscore
</code></pre></div></div>
<p>Open another terminal.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosrun rviz rviz
</code></pre></div></div>
<p>Open another terminal.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosrun gmapping slam_gmapping scan:<span class="o">=</span>scan
</code></pre></div></div>
<p>Open another terminal.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosrun laser_scan_matcher laser_scan_matcher_node _fixed_frame:<span class="o">=</span>odom _max_iterations:<span class="o">=</span>10
</code></pre></div></div>
<p>Open another terminal.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosbag play <span class="nt">--clock</span> <span class="nt">-d</span> 5 tunnel.bag
</code></pre></div></div>

<p><br /></p>

<h1 id="appendix-b-cartographer-slam-in-ros">Appendix B: Cartographer SLAM in ROS</h1>

<h3 id="building-cartographer-ros">Building Cartographer ROS</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> python3-wstool python3-rosdep ninja-build stow
<span class="nb">cd </span>catkin_ws
wstool init src
wstool merge <span class="nt">-t</span> src https://raw.githubusercontent.com/cartographer-project/cartographer_ros/master/cartographer_ros.rosinstall
wstool update <span class="nt">-t</span> src
<span class="nb">sudo </span>rosdep init
</code></pre></div></div>
<p>Ignore the error messages after entering <code class="language-plaintext highlighter-rouge">sudo rosdep init</code>.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosdep update
rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">--rosdistro</span><span class="o">=</span><span class="k">${</span><span class="nv">ROS_DISTRO</span><span class="k">}</span> <span class="nt">-y</span>
</code></pre></div></div>
<p style="text-align: center;"><img src="/assets/projects/Cartographer-Error.png" width="1000" height="250" /></p>
<p>Resolve the error message above by removing line 46 (<code class="language-plaintext highlighter-rouge">&lt;depend&gt;libabsl-dev&lt;/depend&gt;</code>) from the <code class="language-plaintext highlighter-rouge">package.xml</code> file in the cartographer (not cartographer ros) package.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>src/cartographer/scripts/install_abseil.sh
<span class="nb">sudo </span>apt-get remove ros-<span class="k">${</span><span class="nv">ROS_DISTRO</span><span class="k">}</span><span class="nt">-abseil-cpp</span>
catkin_make_isolated <span class="nt">--install</span> <span class="nt">--use-ninja</span>
</code></pre></div></div>
<p>Add the following in the <code class="language-plaintext highlighter-rouge">.bashrc</code> file in the home (<code class="language-plaintext highlighter-rouge">~</code>) directory.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> ~/catkin_ws/install_isolated/setup.bash
</code></pre></div></div>
<p>Reopen the terminal or source the above bash file.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cp </span>install_isolated/share/cartographer_ros/configuration_files/backpack_2d.lua install_isolated/share/cartographer_ros/configuration_files/my_robot.lua
</code></pre></div></div>
<p>Use a code editor to open a Lua file (VSCode was used below).</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>code install_isolated/share/cartographer_ros/configuration_files/backpack_2d.lua
</code></pre></div></div>
<p>Modify the Lua file as follows:</p>
<p style="text-align: center;"><img src="/assets/projects/Cartographer-Lua.png" width="400" height="150" /></p>
<p>Finally, run Cartographer SLAM.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch cartographer_ros demo_my_robot.launch bag_filename:<span class="o">=</span>/home/tyang/tunnel.bag
</code></pre></div></div>

<p><br /></p>

<h1 id="appendix-c-rtab-map-in-ros">Appendix C: RTAB-Map in ROS</h1>

<h3 id="rviz-setup">Rviz Setup</h3>
<p>In order to visualize the point cloud map on Rviz, the following settings are required.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roscore
</code></pre></div></div>
<p>Open another terminal and follow the setup for <code class="language-plaintext highlighter-rouge">LaserScan</code>.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosrun tf static_transform_publisher 0 0 0 0 0 0 base_link map 100
</code></pre></div></div>
<p>Open another terminal and follow the setup for <code class="language-plaintext highlighter-rouge">PointCloud2</code>.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosrun tf static_transform_publisher 0 0 0 2 0 <span class="nt">-1</span>.57 base_link camera_depth_optical_frame 100
</code></pre></div></div>

<h3 id="running-rtab-map">Running RTAB-Map</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>roslaunch rtabmap_launch rtabmap.launch rtabmap_args:<span class="o">=</span><span class="s2">"--delete_db_on_start --Optimizer/GravitySigma 0.3"</span> depth_topic:<span class="o">=</span>/rgbd/camera/depth/image_rect_raw rgb_topic:<span class="o">=</span>/rgbd/camera/color/image_raw camera_info_topic:<span class="o">=</span>/rgbd/camera/color/camera_info approx_sync:<span class="o">=</span><span class="nb">false </span>wait_imu_to_init:<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
</code></pre></div></div>

<p>Open another terminal.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosparam <span class="nb">set </span>use_sim_time <span class="nb">true
</span>rosbag play <span class="nt">--clock</span> tunnel.bag
</code></pre></div></div>
:ET