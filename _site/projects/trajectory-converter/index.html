<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Image to Robot Drawing Trajectory Converter - Tae Yang</title>
<meta name="description" content="Created a program that converted input images (uploaded directly by users or captured with a robot’s fisheye camera) to trajectories that the robot would follow to perform its drawing task.">


  <meta name="author" content="Tae Yang">
  
  <meta property="article:author" content="Tae Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Tae Yang">
<meta property="og:title" content="Image to Robot Drawing Trajectory Converter">
<meta property="og:url" content="http://localhost:4000/projects/trajectory-converter/">


  <meta property="og:description" content="Created a program that converted input images (uploaded directly by users or captured with a robot’s fisheye camera) to trajectories that the robot would follow to perform its drawing task.">







  <meta property="article:published_time" content="2023-07-10T00:00:00-07:00">





  

  


<link rel="canonical" href="http://localhost:4000/projects/trajectory-converter/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Tae Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Tae Yang Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--project wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Tae Yang
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/courses/">Courses</a>
            </li><li class="masthead__menu-item">
              <a href="/projects/">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/studies/">Studies</a>
            </li><li class="masthead__menu-item">
              <a href="/work-experiences/">Work Experiences</a>
            </li><li class="masthead__menu-item">
              <a href="/activities/">Activities</a>
            </li><li class="masthead__menu-item">
              <a href="/resume/">Resume</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile2.png" alt="Tae Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Tae Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Computer Engineering student minoring in Robotics at Northeastern University.<br /><br />Talks about Autonomous Driving, Robotics, SLAM, Computer Vision, and AI/ML</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Boston, MA</span>
        </li>
      

      
        
          
            <li><a href="mailto:yang.tae@northeastern.edu" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/tae-h-yang/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/tae-yang/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://www.instagram.com/hoonyy_11/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Image to Robot Drawing Trajectory Converter">
    <meta itemprop="description" content="Created a program that converted input images (uploaded directly by users or captured with a robot’s fisheye camera) to trajectories that the robot would follow to perform its drawing task.">
    <meta itemprop="datePublished" content="July 10, 2023">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Image to Robot Drawing Trajectory Converter
</h1>
          
        
          <p class="page__meta">Jul 2023 - Aug 2023</p>
        
          <!-- <p>iRobot Intern Hackathon at ,  </p>  -->

        </header>
      

      <section class="page__content" itemprop="text">
        <p>This page is based on the following resources:<br />
<a style="text-decoration: none;" href="https://www.diva-portal.org/smash/get/diva2:1679079/FULLTEXT01.pdf" target="_blank">Paper <i class="fa fa-file"></i></a><br />
<a style="text-decoration: none;" href="https://github.com/tae-h-yang/image-to-robot-drawing-trajectory-converter" target="_blank">Code <i class="fa fa-code"></i></a><br /></p>

<h1 id="introduction">Introduction</h1>
<p>This project was a part of the robot drawing project using a differential wheeled robot for iRobot Inter Hackathon. The robot was equipped with drawing materials and its purpose was to draw objects in reference images. The images were provided either directly from users or from the robot’s fisheye camera which required undistortion. Performing Canny Edge Detection, outlines of the objects in the images were detected and trajectories that the robot should follow while drawing or not drawing were computed connecting the outlines based on closest pixel search. If two outline pixels were far from a certain threshold distance, it was considered as non-drawing area. An additional cascade classifier was used as well in order to detect human faces in the input images and produce better outline results.</p>

<h1 id="test-images">Test Images</h1>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/profile2.jpg" width="170" height="200" /><img src="/assets/projects/trajectory-converter/fisheye_camera_image.jpg" width="300" height="300" /><strong><br />Fig. 1: Profile image and fisheye camera image for testing.</strong></p>

<p>The images in Fig. 1 were tested to produce drawing trajectories for the user input image and robot’s fisheye camera image respectively. For the fisheye camera image, it had to be undistorted first so that the resulting trajectory didn’t look different than the actual object. Also, only the desired objects (the human face and logo) in the images needed to be converted to the trajectories. More tested images and results can be found in <a href="#appendix-a-more-testing-images-and-results">Appendix A</a>.</p>

<h1 id="image-undistortion">Image Undistortion</h1>
<p>The camera image in Fig. 1 had a barrel distortion. This could be simply undistorted using the camera’s intrinsic parameters and distortion coefficients. The parameters and coefficients were provided in advance so camera calibration was not necessary. Detailed procedures for the undistortion can be found in this
<a style="text-decoration: none;" href="https://github.com/tae-h-yang/image-to-robot-drawing-trajectory-converter/blob/main/UndistortImage.ipynb" target="_blank">repo.</a> The resulting undistorted image is shown in Fig. 2 below.</p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/undistorted.jpg" width="300" height="300" /><strong><br />Fig. 2: Undistorted fisheye camera image.</strong></p>

<h1 id="object-outline-detection">Object Outline Detection</h1>
<p>The input images were blurred using a Gaussian kernel to reduce noises and Canny Edge Detection was performed to compute outlines of the objects in the images. For the profile image, a ROI had to be defined to target only the face unless undesired outlines of the background were computed. The ROI was detected using a cascade classifier model in OpenCV was used. The classifier model was effective in detecting frontal faces. The resulting ROI of the profile image is shown in Fig. 3 below.</p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/profile2_detected.png" width="300" height="300" /><strong><br />Fig. 3: ROI of the profile image detected by the cascade classifier.</strong></p>
<p>The resulting outlines of the input images are shown in Fig. 4 below.</p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/profile2_edge_detected.png" width="225" height="200" /><img src="/assets/projects/trajectory-converter/undistorted_edge_detected.png" width="300" height="300" /><strong><br />Fig. 4: Outlines detected by Canny Edge Detection.</strong></p>
<p>Even though the profile image was cropped based on the ROI, there were still some unwanted edges detected from the background. This could be improved by applying filtering methods (erosion and dilation) and tuning the paramters of Canny Edge Detection. Detailed procedures for the ROI and outline detections can be found in this
<a style="text-decoration: none;" href="https://github.com/tae-h-yang/image-to-robot-drawing-trajectory-converter/blob/main/ImageToTrajectoryConverter.py" target="_blank">repo.</a></p>

<h1 id="path-planning-and-trajectory-results">Path Planning and Trajectory Results</h1>
<p>The edges detected were searched through to plan drawing paths. Starting from a edge pixel, its closest edge pixel was searched and connected. If the two pixels were in a specified threshold distance, the connection was considered as a non-drawing area. The resulting drawing trajectories are shown in Fig. 5 below.</p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/profile2_drawing_trajectory.png" width="300" height="200" /><img src="/assets/projects/trajectory-converter/undistorted_drawing_trajectory.png" width="300" height="300" /><strong><br />Fig. 5: Drawing trajectories of the input images.</strong></p>
<p>In Fig. 5, blue lines indicated that the robot should draw while following the paths and red lines indicated that the robot should not draw while following the paths. Detailed procedures for the drawing path planning can be found in this
<a style="text-decoration: none;" href="https://github.com/tae-h-yang/image-to-robot-drawing-trajectory-converter/blob/main/ImageToTrajectoryConverter.py" target="_blank">repo.</a></p>

<h1 id="appendix-a-more-testing-images-and-results">Appendix A: More Testing Images and Results</h1>
<p>Other profile and logo images were tested additionally and demonstrated the performance of the trajectory converter.</p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/profile.jpg" width="200" height="150" /><img src="/assets/projects/trajectory-converter/profile_edge_detected.png" width="200" height="150" /><img src="/assets/projects/trajectory-converter/profile_drawing_trajectory.png" width="300" height="150" /></p>
<p style="text-align: center;"><img src="/assets/projects/trajectory-converter/irobot_logo.png" width="300" height="150" /><img src="/assets/projects/trajectory-converter/irobot_logo_edge_detected.png" width="300" height="150" /><img src="/assets/projects/trajectory-converter/irobot_logo_drawing_trajectory.png" width="300" height="150" /></p>

        
      </section>

      <footer class="page__meta">
        
        


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/projects/vehicle-detection/" class="pagination--pager" title="Multiple Vehicle Detection Utilizing Deep Learning Algorithms
">Previous</a>
    
    
      <a href="/projects/wiimote-create3/" class="pagination--pager" title="Wii-mote Controlled Differential Wheeled Robot
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <!-- <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div> -->

<div class="page__footer-copyright">&copy; 2025 Tae Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
